# =============================================================================
# BiliVagent Configuration File / BiliVagent 配置文件
# =============================================================================
# This file contains all configuration options for BiliVagent
# 此文件包含 BiliVagent 的所有配置选项
#
# Usage / 使用方法:
# 1. Copy this file to .env / 复制此文件为 .env
#    cp .env.example .env
# 2. Fill in your actual values / 填入实际的配置值
# 3. Keep .env file secure and never commit it / 保管好 .env 文件，切勿提交到版本控制
# =============================================================================

# -----------------------------------------------------------------------------
# SiliconFlow API Configuration / SiliconFlow API 配置
# -----------------------------------------------------------------------------
# Get your API key from: https://siliconflow.cn
# 从以下地址获取 API Key: https://siliconflow.cn
# 
# Required: Yes / 必需: 是
SILICONFLOW_API_KEY=your_api_key_here

# SiliconFlow API base URL / SiliconFlow API 基础地址
# Default / 默认: https://api.siliconflow.cn/v1
# Usually no need to change / 通常无需更改
SILICONFLOW_BASE_URL=https://api.siliconflow.cn/v1

# -----------------------------------------------------------------------------
# LLM Model Configuration / 大语言模型配置
# -----------------------------------------------------------------------------
# Text analysis model / 文本分析模型
# Used for: content analysis, keyword extraction, sentiment analysis
# 用途: 内容分析、关键词提取、情感分析
# Recommended / 推荐: Qwen/Qwen2.5-32B-Instruct
# Alternative / 备选: Qwen/Qwen2.5-7B-Instruct (faster, less accurate)
LLM_MODEL=Qwen/Qwen2.5-32B-Instruct

# Vision-Language model / 视觉-语言多模态模型
# Used for: video frame analysis, style recognition
# 用途: 视频画面分析、风格识别
# Recommended / 推荐: Qwen/Qwen2-VL-7B-Instruct
VLM_MODEL=Qwen/Qwen2-VL-7B-Instruct

# -----------------------------------------------------------------------------
# Vosk Speech Recognition Model / Vosk 语音识别模型
# -----------------------------------------------------------------------------
# Path to Vosk model directory / Vosk 模型目录路径
# Download models from: https://alphacephei.com/vosk/models
# 从以下地址下载模型: https://alphacephei.com/vosk/models
#
# Chinese model / 中文模型:
#   - vosk-model-cn-0.22 (recommended, 1.3GB) / 推荐，1.3GB
#   - vosk-model-small-cn-0.22 (smaller, less accurate) / 较小，精度较低
# 
# If not set or model not found, speech recognition will be skipped
# 如果未设置或模型不存在，将跳过语音识别功能
VOSK_MODEL_PATH=./models/vosk-model-cn-0.22

# -----------------------------------------------------------------------------
# Output Configuration / 输出配置
# -----------------------------------------------------------------------------
# Directory for analysis reports / 分析报告输出目录
# Reports will be saved as JSON files / 报告将保存为 JSON 文件
OUTPUT_DIR=./output

# Directory for temporary files (videos, audio, frames) / 临时文件目录（视频、音频、帧）
# Files here can be deleted after analysis / 分析完成后此目录中的文件可以删除
TEMP_DIR=./temp

# -----------------------------------------------------------------------------
# Advanced Options (Optional) / 高级选项（可选）
# -----------------------------------------------------------------------------
# Uncomment and modify if needed / 如需修改请取消注释

# Maximum number of comments to fetch / 获取评论的最大数量
# MAX_COMMENTS=200

# Maximum number of danmaku to fetch / 获取弹幕的最大数量
# MAX_DANMAKU=1000

# Number of video frames to extract for analysis / 提取用于分析的视频帧数
# FRAME_COUNT=3

# Video download quality (best/worst/720p/480p/etc.) / 视频下载质量
# VIDEO_QUALITY=best

# Enable debug logging / 启用调试日志
# DEBUG=false

